{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample program for viterbi decoding\n",
    "# example borrowed from https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/slides/sequence-slides.pdf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decoding(emission_probs, transition_probs, bos_out):\n",
    "    \"\"\"Viterbi algorithm that returns best scored sequence output.\n",
    "    \n",
    "    Args:\n",
    "        emission_probs: [tag_num x l]\n",
    "        transition_probs: [tag_num x tag_num]\n",
    "        bos_out: [tag_num]\n",
    "        \n",
    "        *NOTE: above probs are all in log space, so chain rule\n",
    "            works as addition instead of multiplication\n",
    "    Returns:\n",
    "        best_score: float\n",
    "        best_sequence: [tag_num]\n",
    "    \"\"\"\n",
    "    tag_num, l = emission_probs.shape\n",
    "    v = np.zeros([tag_num, l])\n",
    "    \n",
    "    \n",
    "    # initialize the first step to be emission + transition from <bos>\n",
    "    v[:, 0] = bos_out + emission_probs[:, 0]\n",
    "    \n",
    "    # keep track of sequence\n",
    "    sequence_bptr = []\n",
    "    \n",
    "    for t in range(1, l):\n",
    "        tmp_sum = v[:, t-1] + transition_probs\n",
    "        best_scores = tmp_sum.max(-1)\n",
    "        best_pred = tmp_sum.argmax(-1)\n",
    "        \n",
    "        v[:, t] = best_scores + emission_probs[:, t]\n",
    "        sequence_bptr.append(best_pred)\n",
    "        \n",
    "        \n",
    "    best_score = max(v[:, l - 1])\n",
    "    best_seq = [None for _ in range(l)]\n",
    "    cur_ptr = v[:, l - 1].argmax()\n",
    "    \n",
    "#     best_seq[-1] = cur_ptr\n",
    "    for t in range(l - 1, 0, -1):\n",
    "        predecessor = sequence_bptr[t - 1][cur_ptr]\n",
    "        best_seq[t] = cur_ptr\n",
    "        cur_ptr = predecessor\n",
    "        \n",
    "    best_seq[0] = predecessor\n",
    "    return best_score, best_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_probs = np.array([\n",
    "    [-2, -10], [-3, -1], [-3, -3]\n",
    "]).transpose()\n",
    "\n",
    "transition_probs = np.array([\n",
    "        [-3, -1],\n",
    "        [-1, -3]\n",
    "    ])\n",
    "bos_out = np.array([-1, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_score, b_seq = viterbi_decoding(emission_probs, transition_probs, bos_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
